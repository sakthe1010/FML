{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CODE TO CREATE TRAIN AND VERIFICATION TEST DATA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will Ã¼ b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Category                                            Message\n",
       "0         ham  Go until jurong point, crazy.. Available only ...\n",
       "1         ham                      Ok lar... Joking wif u oni...\n",
       "2        spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3         ham  U dun say so early hor... U c already then say...\n",
       "4         ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...       ...                                                ...\n",
       "5567     spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568      ham              Will Ã¼ b going to esplanade fr home?\n",
       "5569      ham  Pity, * was in mood for that. So...any other s...\n",
       "5570      ham  The guy did some bitching but I acted like i'd...\n",
       "5571      ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_df = pd.read_csv(\"train dataset.csv\", encoding = \"ISO-8859-1\")\n",
    "master_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sakth\\AppData\\Local\\Temp\\ipykernel_14572\\3610428285.py:11: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  row_data = str(row[1])  # Assuming the column is unnamed or you want the first column\n"
     ]
    }
   ],
   "source": [
    "master_df_test = pd.DataFrame(master_df).iloc[5000:].reset_index(drop = True, inplace = False).rename(columns={\"Category\":\"label\", \"Message\":\"message\"})\n",
    "master_df_train = pd.DataFrame(master_df).iloc[0:5000].reset_index(drop = True, inplace = False).rename(columns={\"Category\":\"label\", \"Message\":\"message\"})\n",
    "\n",
    "\n",
    "if not os.path.exists(\"test\"):\n",
    "    os.makedirs(\"test\")\n",
    "\n",
    "for index, row in master_df_test.iterrows():\n",
    "\n",
    "    \n",
    "    row_data = str(row[1])  # Assuming the column is unnamed or you want the first column\n",
    "    \n",
    "    # Define a filename for each text file\n",
    "    filename = os.path.join(\"test\", f\"email{index+1}.txt\")\n",
    "    \n",
    "    # Write the row data to a text file\n",
    "    with open(filename, \"w\", encoding = \"ISO-8859-1\") as f:\n",
    "        f.write(row_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Hmph. Go head, big baller.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Well its not like you actually called someone ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nope. Since ayo travelled, he has forgotten hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>You still around? Looking to pick up later</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spam</td>\n",
       "      <td>CDs 4u: Congratulations ur awarded Â£500 of CD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will Ã¼ b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    label                                            message\n",
       "0     ham                         Hmph. Go head, big baller.\n",
       "1     ham  Well its not like you actually called someone ...\n",
       "2     ham  Nope. Since ayo travelled, he has forgotten hi...\n",
       "3     ham         You still around? Looking to pick up later\n",
       "4    spam  CDs 4u: Congratulations ur awarded Â£500 of CD...\n",
       "..    ...                                                ...\n",
       "567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "568   ham              Will Ã¼ b going to esplanade fr home?\n",
       "569   ham  Pity, * was in mood for that. So...any other s...\n",
       "570   ham  The guy did some bitching but I acted like i'd...\n",
       "571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[572 rows x 2 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_y_true = master_df_test[\"label\"]\n",
    "master_y_true.to_csv(\"y_true.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = master_df_train "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACTUAL CODE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess text data\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = re.sub(r'\\W', ' ', text)  # Remove special characters and punctuation\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra spaces\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['message'] = dataset['message'].apply(preprocess_text)\n",
    "X_train = dataset['message'].values\n",
    "\n",
    "# Convert labels to binary format (1 for spam, 0 for ham)\n",
    "dataset['label'] = dataset['label'].map({'spam': 1, 'ham': 0})\n",
    "y_train = dataset['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['go until jurong point crazy available only in bugis n great world la e buffet cine there got amore wat',\n",
       "       'ok lar joking wif u oni',\n",
       "       'free entry in 2 a wkly comp to win fa cup final tkts 21st may 2005 text fa to 87121 to receive entry question std txt rate t c s apply 08452810075over18 s',\n",
       "       ..., 'happy new year hope you are having a good semester',\n",
       "       'esplanade lor where else', 'can you talk with me'], dtype=object)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual Feature Extraction using Bag of Words\n",
    "def build_vocabulary(messages, vocab_size=1000):\n",
    "    # Tokenize and count word frequencies across all messages\n",
    "    word_counts = Counter()\n",
    "    for message in messages:\n",
    "        words = message.split()\n",
    "        word_counts.update(words)\n",
    "    \n",
    "    # Select the top `vocab_size` words as the vocabulary\n",
    "    vocabulary = [word for word, _ in word_counts.most_common(vocab_size)]\n",
    "    return vocabulary\n",
    "\n",
    "def message_to_vector(message, vocabulary):\n",
    "    words = message.split()\n",
    "    word_count = Counter(words)\n",
    "    # Create a vector of size `vocab_size` where each position represents a word count in the vocabulary\n",
    "    vector = [word_count[word] if word in word_count else 0 for word in vocabulary]\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of spam messages: 673\n",
      "Number of ham messages: 4327\n"
     ]
    }
   ],
   "source": [
    "# Separate the dataset into spam and ham\n",
    "spam_data = dataset[dataset['label'] == 1]\n",
    "ham_data = dataset[dataset['label'] == 0]\n",
    "\n",
    "print(\"Number of spam messages:\", len(spam_data))\n",
    "print(\"Number of ham messages:\", len(ham_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oversample spam data to match the size of ham data\n",
    "oversampled_spam_data = spam_data.sample(len(ham_data), replace=True)\n",
    "balanced_data = pd.concat([ham_data, oversampled_spam_data])\n",
    "\n",
    "# Shuffle the balanced dataset  \n",
    "balanced_data = balanced_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Extract messages and labels\n",
    "X_train = balanced_data['message']\n",
    "y_train = balanced_data['label'].values\n",
    "\n",
    "\n",
    "# # Rebuild the vocabulary and feature matrix for the balanced data\n",
    "# vocabulary = build_vocabulary(X)\n",
    "# X_balanced = np.array([message_to_vector(message, vocabulary) for message in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"test\" \n",
    "data = []\n",
    "\n",
    "if not os.path.exists(\"test\"):\n",
    "    print(\"test folder does not exist\")\n",
    "    \n",
    "if not os.path.exists(folder_path):\n",
    "    print(f\"{folder_path} folder does not exist\")\n",
    "else:\n",
    "    # Sort filenames numerically by extracting the numeric part\n",
    "    filenames = sorted(os.listdir(folder_path), key=lambda x: int(x.split('.')[0].replace('email', '')))\n",
    "    \n",
    "    # Loop through each sorted file\n",
    "    for filename in filenames:\n",
    "        if filename.endswith(\".txt\"):  # Check for .txt files\n",
    "            file_path = os.path.join(folder_path, filename)  # Full path to the file\n",
    "            \n",
    "            # Read the file content\n",
    "            with open(file_path, \"r\", encoding=\"ISO-8859-1\") as file:\n",
    "                content = file.read().strip()  # Read and strip whitespace/newlines\n",
    "                \n",
    "            # Append the content to the list\n",
    "            data.append({\"message\": content})\n",
    "\n",
    "# Create a DataFrame from the list\n",
    "master_df_test = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hmph. Go head, big baller.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Well its not like you actually called someone ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nope. Since ayo travelled, he has forgotten hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You still around? Looking to pick up later</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CDs 4u: Congratulations ur awarded Â£500 of CD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>Will Ã¼ b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>572 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               message\n",
       "0                           Hmph. Go head, big baller.\n",
       "1    Well its not like you actually called someone ...\n",
       "2    Nope. Since ayo travelled, he has forgotten hi...\n",
       "3           You still around? Looking to pick up later\n",
       "4    CDs 4u: Congratulations ur awarded Â£500 of CD...\n",
       "..                                                 ...\n",
       "567  This is the 2nd time we have tried 2 contact u...\n",
       "568              Will Ã¼ b going to esplanade fr home?\n",
       "569  Pity, * was in mood for that. So...any other s...\n",
       "570  The guy did some bitching but I acted like i'd...\n",
       "571                         Rofl. Its true to its name\n",
       "\n",
       "[572 rows x 1 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract messages and labels\n",
    "X_test = master_df_test['message'].values\n",
    "\n",
    "# Preprocess text data\n",
    "X_test = [preprocess_text(text) for text in X_test]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_score(y_true, y_pred):\n",
    "    pred = np.sum(y_true == y_pred)\n",
    "    acc = pred / len(y_true)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=1000, stop_words='english', ngram_range=(1, 2))\n",
    "X_train =vectorizer.fit_transform(X_train).toarray()\n",
    "X_test = vectorizer.transform(X_test).toarray()\n",
    "\n",
    "y_test = pd.read_csv(\"y_true.csv\", header=None, skiprows=1)\n",
    "y_test = y_test[0].map({'spam': 1, 'ham': 0})\n",
    "y_test=y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8654, 1000)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes Classifier from Scratch\n",
    "class NaiveBayesClassifier:\n",
    "    def __init__(self):\n",
    "        self.word_probs = {}\n",
    "        self.class_probs = {}\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Calculate prior probabilities\n",
    "        self.class_probs[1] = np.mean(y == 1)  # Probability of spam\n",
    "        self.class_probs[0] = np.mean(y == 0)  # Probability of ham\n",
    "        \n",
    "        # Separate spam and ham messages\n",
    "        spam_messages = X[y == 1]\n",
    "        ham_messages = X[y == 0]\n",
    "        \n",
    "        # Calculate total word counts for each class\n",
    "        total_spam_words = np.sum(spam_messages)\n",
    "        total_ham_words = np.sum(ham_messages)\n",
    "        \n",
    "        # Calculate word probabilities given each class\n",
    "        self.word_probs[1] = (np.sum(spam_messages, axis=0) + 1) / (total_spam_words + X.shape[1])\n",
    "        self.word_probs[0] = (np.sum(ham_messages, axis=0) + 1) / (total_ham_words + X.shape[1])\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        for message in X:\n",
    "            # Calculate log-probabilities for spam and ham\n",
    "            log_spam_prob = np.log(self.class_probs[1])\n",
    "            log_ham_prob = np.log(self.class_probs[0])\n",
    "            for i, word_count in enumerate(message):\n",
    "                if word_count > 0:  # Only consider words that appear in the message\n",
    "                    log_spam_prob += word_count * np.log(self.word_probs[1][i])\n",
    "                    log_ham_prob += word_count * np.log(self.word_probs[0][i])\n",
    "            # Choose the class with higher log-probability\n",
    "            predictions.append(1 if log_spam_prob > log_ham_prob else 0)\n",
    "        return np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9772727272727273\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99       498\n",
      "           1       0.89      0.95      0.92        74\n",
      "\n",
      "    accuracy                           0.98       572\n",
      "   macro avg       0.94      0.96      0.95       572\n",
      "weighted avg       0.98      0.98      0.98       572\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "# Initialize and train the Naive Bayes classifier\n",
    "nb_classifier = NaiveBayesClassifier()\n",
    "nb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = nb_classifier.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy_nb = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_nb}\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9842657342657343\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       498\n",
      "           1       0.96      0.92      0.94        74\n",
      "\n",
      "    accuracy                           0.98       572\n",
      "   macro avg       0.97      0.96      0.96       572\n",
      "weighted avg       0.98      0.98      0.98       572\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc_classifier = SVC()\n",
    "svc_classifier.fit(X_train, y_train)\n",
    "y_pred = svc_classifier.predict(X_test)\n",
    "accuracy_svc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy_svc}\")\n",
    "print(classification_report(y_test, y_pred))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNearestNeighborsClassifier:\n",
    "    def __init__(self, k=3):\n",
    "        self.k = k\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        for x in X:\n",
    "            distances = np.sqrt(np.sum((self.X_train - x) ** 2, axis=1))  # Calculate Euclidean distance\n",
    "            k_nearest_indices = distances.argsort()[:self.k]  # Get indices of k nearest neighbors\n",
    "            k_nearest_labels = self.y_train[k_nearest_indices]  # Get the labels of those neighbors\n",
    "            majority_vote = Counter(k_nearest_labels).most_common(1)[0][0]  # Majority vote\n",
    "            predictions.append(majority_vote)\n",
    "        return np.array(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "K-Nearest Neighbors (K=3) Performance:\n",
      "Accuracy: 0.9632867132867133\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       498\n",
      "           1       0.91      0.80      0.85        74\n",
      "\n",
      "    accuracy                           0.96       572\n",
      "   macro avg       0.94      0.89      0.91       572\n",
      "weighted avg       0.96      0.96      0.96       572\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train the K-Nearest Neighbors classifier\n",
    "knn_classifier = KNearestNeighborsClassifier(k=3)\n",
    "knn_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_knn = knn_classifier.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "\n",
    "print(\"\\nK-Nearest Neighbors (K=3) Performance:\")\n",
    "print(f\"Accuracy: {accuracy_knn}\")\n",
    "print(classification_report(y_test, y_pred_knn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeClassifierCustom:\n",
    "    def __init__(self, depth=10):\n",
    "        self.depth = depth\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.tree = self._build_tree(X, y, depth=self.depth)\n",
    "\n",
    "    def _build_tree(self, X, y, depth):\n",
    "        # Base cases for stopping recursion\n",
    "        if len(set(y)) == 1 or depth == 0:\n",
    "            return Counter(y).most_common(1)[0][0]\n",
    "        \n",
    "        # Find best split\n",
    "        best_feature, best_threshold = self._best_split(X, y)\n",
    "        if best_feature is None:\n",
    "            return Counter(y).most_common(1)[0][0]\n",
    "        \n",
    "        # Split dataset\n",
    "        left_indices = X[:, best_feature] <= best_threshold\n",
    "        right_indices = X[:, best_feature] > best_threshold\n",
    "        \n",
    "        left_subtree = self._build_tree(X[left_indices], y[left_indices], depth-1)\n",
    "        right_subtree = self._build_tree(X[right_indices], y[right_indices], depth-1)\n",
    "        \n",
    "        return (best_feature, best_threshold, left_subtree, right_subtree)\n",
    "\n",
    "    def _best_split(self, X, y):\n",
    "        best_gain = 0\n",
    "        best_feature, best_threshold = None, None\n",
    "        # Loop over each feature to find the best split\n",
    "        for feature in range(X.shape[1]):\n",
    "            thresholds = np.unique(X[:, feature])\n",
    "            for threshold in thresholds:\n",
    "                gain = self._information_gain(y, X[:, feature], threshold)\n",
    "                if gain > best_gain:\n",
    "                    best_gain = gain\n",
    "                    best_feature = feature\n",
    "                    best_threshold = threshold\n",
    "        return best_feature, best_threshold\n",
    "\n",
    "    def _information_gain(self, y, feature_column, threshold):\n",
    "        # Calculate information gain for a specific split\n",
    "        left = y[feature_column <= threshold]\n",
    "        right = y[feature_column > threshold]\n",
    "        if len(left) == 0 or len(right) == 0:\n",
    "            return 0\n",
    "        p = len(left) / len(y)\n",
    "        return self._entropy(y) - (p * self._entropy(left) + (1 - p) * self._entropy(right))\n",
    "\n",
    "    def _entropy(self, y):\n",
    "        # Calculate entropy\n",
    "        proportions = np.bincount(y) / len(y)\n",
    "        return -np.sum([p * np.log2(p) for p in proportions if p > 0])\n",
    "\n",
    "    def _predict(self, node, x):\n",
    "        # Recursively traverse the tree\n",
    "        if not isinstance(node, tuple):\n",
    "            return node\n",
    "        feature, threshold, left, right = node\n",
    "        if x[feature] <= threshold:\n",
    "            return self._predict(left, x)\n",
    "        else:\n",
    "            return self._predict(right, x)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self._predict(self.tree, x) for x in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decision Tree Performance:\n",
      "Accuracy: 0.9300699300699301\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96       498\n",
      "           1       0.80      0.61      0.69        74\n",
      "\n",
      "    accuracy                           0.93       572\n",
      "   macro avg       0.87      0.79      0.83       572\n",
      "weighted avg       0.93      0.93      0.93       572\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train the Decision Tree classifier\n",
    "tree_classifier = DecisionTreeClassifierCustom(depth=5)\n",
    "tree_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_tree = tree_classifier.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy_tree = accuracy_score(y_test, y_pred_tree)\n",
    "\n",
    "print(\"\\nDecision Tree Performance:\")\n",
    "print(f\"Accuracy: {accuracy_tree}\")\n",
    "print(classification_report(y_test, y_pred_tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegressionClassifier:\n",
    "    def __init__(self, lr=0.01, epochs=1000):\n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.weights = np.zeros(X.shape[1])\n",
    "        self.bias = 0\n",
    "        for _ in range(self.epochs):\n",
    "            linear_model = np.dot(X, self.weights) + self.bias\n",
    "            y_pred = self.sigmoid(linear_model)\n",
    "            # Gradient descent updates\n",
    "            dw = (1 / len(y)) * np.dot(X.T, (y_pred - y))\n",
    "            db = (1 / len(y)) * np.sum(y_pred - y)\n",
    "            self.weights -= self.lr * dw\n",
    "            self.bias -= self.lr * db\n",
    "\n",
    "    def predict(self, X):\n",
    "        linear_model = np.dot(X, self.weights) + self.bias\n",
    "        y_pred = self.sigmoid(linear_model)\n",
    "        return [1 if i > 0.5 else 0 for i in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression Performance:\n",
      "Accuracy: 0.972027972027972\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98       498\n",
      "           1       0.84      0.97      0.90        74\n",
      "\n",
      "    accuracy                           0.97       572\n",
      "   macro avg       0.92      0.97      0.94       572\n",
      "weighted avg       0.98      0.97      0.97       572\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train the Logistic Regression classifier\n",
    "logistic_classifier = LogisticRegressionClassifier(lr=0.01, epochs=1000)\n",
    "logistic_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_logistic = logistic_classifier.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy_logistic = accuracy_score(y_test, y_pred_logistic)\n",
    "\n",
    "print(\"\\nLogistic Regression Performance:\")\n",
    "print(f\"Accuracy: {accuracy_logistic}\")\n",
    "print(classification_report(y_test, y_pred_logistic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique elements: [0 1]\n",
      "Counts: [498  74]\n",
      "Frequency dictionary: {np.int64(0): np.int64(498), np.int64(1): np.int64(74)}\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "y_test = np.array(y_test)\n",
    "unique_elements, counts = np.unique(y_test, return_counts=True)\n",
    "frequency_dict = dict(zip(unique_elements, counts))\n",
    "\n",
    "print(\"Unique elements:\", unique_elements)\n",
    "print(\"Counts:\", counts)\n",
    "print(\"Frequency dictionary:\", frequency_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
